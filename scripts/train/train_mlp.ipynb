{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPL Training\n",
    "\n",
    "This notebook goes over the steps to train the MLP network.\n",
    "As mentioned in the paper, we use 14 batches as training traces and 6 batches for verification traces. These verification traces will be used to select the optimal MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'   # Disable tensorflow logs\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.fft import fft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and methods definitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras generator\n",
    "\n",
    "The traces may not all fit into memory, which is why we need a generator.\n",
    "\n",
    "Adapted from https://github.com/angulartist/Keras-HDF5-ImageDataGenerator  \n",
    "Copyright (c) 2023, Jesse De Meulemeester  \n",
    "Copyright (c) 2017, HDF5 ImageDataGenerator All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Generator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Just a simple custom Keras HDF5 Generator.\n",
    "    \n",
    "    Custom Keras ImageDataGenerator that generates\n",
    "    batches of traces from HDF5 files\n",
    "     \n",
    "    Arguments\n",
    "    ---------\n",
    "    src : str\n",
    "        Path of the hdf5 source file.\n",
    "    x_key : str\n",
    "        Key of the h5 file image tensors dataset.\n",
    "    y_key : str\n",
    "        Key of the h5 file labels dataset.\n",
    "    classes_key : str\n",
    "        Key of the h5 file dataset containing\n",
    "        the raw classes.\n",
    "    batch_size : int\n",
    "        Size of each batch, must be a power of two.\n",
    "        (16, 32, 64, 128, 256, ...)\n",
    "        Default is 32.\n",
    "    shuffle : bool\n",
    "        Shuffle images at the end of each epoch.\n",
    "        Default is True.\n",
    "    indices : np.ndarray\n",
    "        Indices of the traces to use. None will use all available traces.\n",
    "        Default is None.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        f: h5py.File,\n",
    "        x_key: str,\n",
    "        y_key: str,\n",
    "        classes_key: str,\n",
    "        batch_size: int = 32,\n",
    "        shuffle: bool = True,\n",
    "        indices: np.ndarray = None\n",
    "    ):\n",
    "        self.f: h5py.File = f\n",
    "        self.x_key: str = x_key\n",
    "        self.y_key: str = y_key\n",
    "        self.classes_key: str = classes_key\n",
    "        self.batch_size: int = batch_size\n",
    "        self.shuffle: bool = shuffle\n",
    "\n",
    "        if indices is None:\n",
    "            self._indices = np.arange(self.__get_dataset_shape(self.x_key, 0))\n",
    "        else:\n",
    "            self._indices = indices\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Representation of the class.\"\"\"\n",
    "        return f\"{self.__class__.__name__}({self.__dict__!r})\"\n",
    "\n",
    "    def __get_dataset_shape(self, dataset: str, index: int):\n",
    "        \"\"\"Get an h5py dataset shape.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        dataset : str\n",
    "            The dataset key.\n",
    "        index : int\n",
    "            The dataset index.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ints\n",
    "            A tuple of array dimensions.\n",
    "        \"\"\"\n",
    "        return self.f[self.classes_key][dataset].shape[index]\n",
    "\n",
    "    def __get_dataset_items(\n",
    "        self,\n",
    "        indices: np.ndarray,\n",
    "    ):\n",
    "        \"\"\"Get an HDF5 dataset items.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        indices : ndarray, \n",
    "            The list of current batch indices.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        a tuple of ndarrays\n",
    "            A batch of samples.\n",
    "        \"\"\"\n",
    "        return (self.f[self.classes_key][self.x_key][indices], self.f[self.classes_key][self.y_key][indices])\n",
    "    \n",
    "    @property\n",
    "    def num_items(self):\n",
    "        \"\"\"Grab the total number of examples\n",
    "         from the dataset.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of examples.\n",
    "        \"\"\"\n",
    "        self.f[self.classes_key][self.x_key].shape[0]\n",
    "    \n",
    "    @property \n",
    "    def classes(self):\n",
    "        \"\"\"Grab \"human\" classes from the dataset.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of the raw classes.\n",
    "        \"\"\"      \n",
    "        return self.f[self.classes_key][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of batches per epochs.\n",
    "        \"\"\"\n",
    "        return len(self._indices) // self.batch_size\n",
    "\n",
    "    def __next_batch(self,\n",
    "                     indices: np.ndarray):\n",
    "        \"\"\"Generates a batch of train/val data for the given indices.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels.\n",
    "        \"\"\"\n",
    "        # Grab samples (tensors, labels) HDF5 source file.\n",
    "        return self.__get_dataset_items(indices)\n",
    "\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int):\n",
    "        \"\"\"Generates a batch of data for the given index.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the current batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays or ndarray\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels (train) or\n",
    "            a tuple of image tensors (predict).\n",
    "        \"\"\"\n",
    "        # Indices for the current batch.\n",
    "        indices = np.sort(self._indices[index * self.batch_size:(index + 1) *\n",
    "                                        self.batch_size])\n",
    "\n",
    "        return self.__next_batch(indices)\n",
    "\n",
    "    def __shuffle_indices(self):\n",
    "        \"\"\"If the shuffle parameter is set to True,\n",
    "         dataset will be shuffled (in-place).\n",
    "        \"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Triggered once at the very beginning as well as \n",
    "         at the end of each epoch.\n",
    "        \"\"\"\n",
    "        self.__shuffle_indices()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training and evaluation datasets\n",
    "\n",
    "We now transform the input traces into the actual parts we will use. For each trace, we keep the 1000 lowerest frequency components when taking the FFT over the optimal window. We store these components for each trace in a new file which we will use during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directories containing the training and validation traces\n",
    "directory_train = \"../traces/4-mlp-data/0-base-experiments/spectrem/cf/setup-a/training-data/\"\n",
    "directory_val   = \"../traces/4-mlp-data/0-base-experiments/spectrem/cf/setup-a/validation-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random string used in the POC SpectrEM implementations\n",
    "data = b\"data|\\x01\\x36\\x9b\\x78\\xc9\\x2c\\x3d\\x32\\xfa\\x83\\x50\\xaf\\x39\\xaf\\x69\\x2d\\x58\\xd7\\x38\\x6a\\xc1\\x63\\x15\\xc7\\x3c\\x4d\\x96\\x61\\xe1\\x88\\xbd\\xed\"\n",
    "data = np.frombuffer(data, dtype=np.uint8)\n",
    "def get_bit_sp(index):\n",
    "    \"\"\"Get the bit corresponding to the given inputs\n",
    "    \n",
    "    @param index The index for which to get the corresponding bit\"\"\"\n",
    "    return (data[index // 8] & (1 << (index % 8))).astype(bool)\n",
    "\n",
    "def get_bit_md(inputs):\n",
    "    \"\"\"Get the bit corresponding to the given inputs for MeltEMdown\n",
    "    \n",
    "    @param inputs The inputs for which to retrieve the secret bit\"\"\"\n",
    "    return inputs[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in (directory_train, directory_val):\n",
    "    files = [f for f in os.listdir(dir) if f.endswith(\".hdf5\") and f != \"mlp-data.hdf5\"]\n",
    "    with h5py.File(f\"{dir}/mlp-data.hdf5\", 'x', libver='latest') as f:\n",
    "        expg = f.create_group(\"data\")\n",
    "        freqsDset = expg.create_dataset(\"traces\", (len(files)*4096*4, 1000), dtype='float32')\n",
    "        expectedDset = expg.create_dataset(\"expected\", (len(files)*4096*4, 2), dtype='uint8')\n",
    "        traces_i = 0\n",
    "\n",
    "        for file in tqdm(files):\n",
    "            with h5py.File(f\"{dir}/{file}\", 'r', libver='latest') as f_traces:\n",
    "                traces = f_traces['data']['traces']\n",
    "                inputs = f_traces['data']['inputs']\n",
    "\n",
    "                window_start = f_traces.attrs[\"optimal_window_start\"]\n",
    "                window = slice(window_start, window_start+5000)\n",
    "\n",
    "                for i in range(traces.shape[0]):\n",
    "                    freqsDset[traces_i,:] = np.abs(fft(traces[i,window]))[:1000]\n",
    "\n",
    "                    # Note: Change the get_bit function in case of MeltEMdown traces, or when training a network for the case study\n",
    "                    expectedDset[traces_i, get_bit_sp(inputs[i])] = 1\n",
    "                    traces_i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network\n",
    "\n",
    "We now define the MLP network that we will use for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_train = f\"{directory_train}/mlp-data.hdf5\"\n",
    "fname_val = f\"{directory_val}/mlp-data.hdf5\"\n",
    "    \n",
    "f_train = h5py.File(fname_train, 'r', libver='latest')\n",
    "f_val = h5py.File(fname_val, 'r', libver='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "  Total number of traces: 327680\n",
      "    Of which 229376 are used to train the network\n",
      "    Of which 98304 are used to validate the network\n",
      "  Batch size: 32\n",
      "    Resulting in 7168 steps per epoch for training\n",
      "    Resulting in 3072 steps per epoch for validation\n"
     ]
    }
   ],
   "source": [
    "N_TRAIN = f_train[\"data\"][\"traces\"].shape[0]\n",
    "N_VAL = f_val[\"data\"][\"traces\"].shape[0]\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "VALIDATION_STEPS = N_VAL // BATCH_SIZE\n",
    "\n",
    "print(f\"Summary:\")\n",
    "print(f\"  Total number of traces: {N_TRAIN + N_VAL}\")\n",
    "print(f\"    Of which {N_TRAIN} are used to train the network\")\n",
    "print(f\"    Of which {N_VAL} are used to validate the network\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"    Resulting in {STEPS_PER_EPOCH} steps per epoch for training\")\n",
    "print(f\"    Resulting in {VALIDATION_STEPS} steps per epoch for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.0001,\n",
    "  decay_steps=STEPS_PER_EPOCH * 10,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = HDF5Generator(f_train, \"traces\", \"expected\", \"data\", indices=None, batch_size=BATCH_SIZE)\n",
    "validation_generator = HDF5Generator(f_val, \"traces\", \"expected\", \"data\", indices=None, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(1000, dtype=\"float64\"),\n",
    "    tf.keras.layers.Dense(500, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(200, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_crossentropy', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               500500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               100200    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621,002\n",
      "Trainable params: 621,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_checkpoint = f\"{directory_train}/mlp_checkpoints/saved-model-{{epoch:03d}}-{{val_accuracy:.5f}}.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath_checkpoint, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list = [checkpoint, tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=20, restore_best_weights=True)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now start the actual training.\n",
    "Note that we used early stopping with patience 20. To get the best model, retrieve the model 20 epochs before the last model from the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x = training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "    validation_steps = VALIDATION_STEPS,\n",
    "    epochs=1000,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('letsgetphysical')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ad583c4c013fce90e8ce0308c17365f7d912fe91c0aacff7e52a3a38123cd99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
